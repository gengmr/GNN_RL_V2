面向训练稳定性的系统性改进方案 (最终优化版 v2)
本方案通过重构强化学习框架中的两大核心信号——输入特征与价值监督——旨在从根本上解决训练不稳定的问题。方案遵循问题内蕴基准 (Problem-Intrinsic Baseline) 和 信号动态扩展 (Signal Dynamic Expansion) 两大核心原则，以确保模型在一个科学、一致且信息丰富的环境中高效学习。
模块一：基于HEFT基准的自适应输入特征归一化
1.1. 核心方法
我们采用一种问题内蕴的自适应归一化方法。此方法的核心在于，用一个与问题实例自身特性紧密相关的静态尺度因子，来替代原方案中那个跨问题的、全局动态更新的historical_avg_makespan。这个新的尺度因子被称为normalization_scale。
1.2. 尺度因子的科学定义
normalization_scale被严谨地定义为该问题实例在高性能启发式算法HEFT下的调度完工时间（makespan）。
self.normalization_scale = heft_makespan
在heft_makespan完全为零的极端情况（例如，一个没有任何任务的空问题），为保证数值稳定性，尺度因子将被设置为一个标准单位值1.0。因此，完整的定义是：
self.normalization_scale = heft_makespan if heft_makespan > 0 else 1.0
1.3. 归一化应用与替换逻辑
应用对象: normalization_scale因子将被用于环境中所有与绝对时间相关的动态状态变量，主要包括processor_available_times和task_finish_times。
替换过程:
移除旧机制: 彻底移除在trainer.py和mcts.py中向状态字典注入historical_avg_makespan的逻辑，并删除模型前向传播中对该变量的依赖。
植入新机制: 在环境的reset方法中，计算一次heft_makespan并将其赋值给self.normalization_scale。随后，在get_state方法中，所有时间相关的状态变量在输出前，都将除以这个在当前episode中固定不变的self.normalization_scale。
方法论优势:
稳定取代动态: 用一个在单局游戏内静态、固定的尺度，取代了那个在整个训练过程中动态、漂移的全局尺度，从根本上解决了输入特征分布不稳定的问题。
内蕴取代全局: 用一个问题内蕴的尺度（只与当前问题相关），取代了那个全局的尺度（与所有历史问题相关），解决了“苹果与橘子”式的非公平比较问题，使得归一化更具科学性和合理性。
模块二：基于平滑非对称区间映射的扩展价值目标
2.1. 核心方法
为精确反映您对性能区间的经验判断，并确保映射函数的平滑性与合理性，我们设计了一种平滑的、非对称的区间映射方法。该方法将原始的性能比率，通过一个连续的、分段线性的函数，映射到一个能充分利用tanh函数有效梯度的得分空间。
2.2. 价值目标的优化定义
价值目标target_value的计算将遵循一个精细、平滑且完全符合您要求的四步流程：
获取双方表现: 记录强化学习Agent的makespan_RL和HEFT基准的makespan_HEFT。
计算原始性能比率 (Performance Ratio):
performance_ratio = makespan_RL / makespan_HEFT
这是所有后续计算的基础。
平滑的非对称区间映射 (Smooth Asymmetric Interval Mapping):
我们定义三个关键锚点来构建一个连续的分段线性函数：
上限锚点 (Upper Anchor): ratio = 0.95 映射为 score = +1.0 (代表预期的优秀性能边界)。
中心锚点 (Center Anchor): ratio = 1.0 映射为 score = 0.0 (代表与HEFT持平)。
下限锚点 (Lower Anchor): ratio = 1.2 映射为 score = -1.0 (代表预期的较差性能边界)。
expanded_score 的计算方法如下，此设计保证了在ratio = 1.0处是完全平滑和连续的：
当 performance_ratio <= 1.0 (性能超越HEFT):
expanded_score = (1.0 - performance_ratio) / (1.0 - 0.95)
此公式将 [0.95, 1.0] 的性能比率区间线性映射到 [+1.0, 0.0] 的得分区间。
当 performance_ratio > 1.0 (性能落后HEFT):
expanded_score = (1.0 - performance_ratio) / (1.2 - 1.0)
此公式将 (1.0, 1.2] 的性能比率区间线性映射到 (0.0, -1.0] 的得分区间。
合理性分析:
平滑性: 函数在ratio = 1.0处是连续的，两侧的导数虽然不同（反映了非对称性），但函数值本身无跳变，保证了学习目标的平滑性。
非对称性: 该设计精确地 반영了您的经验：性能提升的空间 (1.0 - 0.95 = 0.05) 比性能下降的空间 (1.2 - 1.0 = 0.2) 更窄。这意味着，微小的性能提升会被放大成更显著的得分变化，从而给予模型更强的正向激励信号，而性能的轻微下降则会被更温和地惩罚。这是一种非常合理的、符合问题特性的设计。
最终非线性压缩:
对expanded_score进行裁剪（clip）以处理超出典型性能区间的极端情况，然后通过tanh函数进行最终的平滑压缩。
final_score = clip(expanded_score, -3.0, 3.0)
target_value = tanh(final_score)
裁剪 (Clipping): 将得分限制在一个例如[-3, 3]的范围内，可以防止极端离群的性能（例如ratio=0.5或ratio=3.0）产生过大的expanded_score，从而避免tanh函数进入梯度饱和区（梯度几乎为零），保证了即使在极端情况下模型依然能接收到有效的学习信号。
2.3. 模型架构适配
神经网络的价值头输出层必须添加一个tanh激活函数，以确保模型的预测值与target_value的[-1, 1]范围严格匹配。